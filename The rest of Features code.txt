	//this list will hold the feature point locations
	std::vector<cv::Point2f> goodPts1, goodPts2;

	//choose only the matches whose matches are significatly better than the second best matches
	std::vector<cv::DMatch> goodMatches;
	for (const auto& match : matches1) {
		if (match[0].distance < 0.8 * match[1].distance) {
			goodMatches.push_back(match[0]);

			//names are a carry over from SIFTS original use as object recognition 
			//query points are to be matched to training points
			goodPts1.push_back(keypoints1[match[0].queryIdx].pt);
			goodPts2.push_back(keypoints2[match[0].trainIdx].pt);
		}
	}

	//compute homography
	std::vector<unsigned char> inliers;
	cv::Mat H = cv::findHomography(goodPts2, goodPts1, inliers, cv::RANSAC);

	//print homography
	std::cout << H << std::endl;

	//define the corners of imageToTest
	cv::Mat c1(3, 1, CV_64F);
	c1.at<double>(0, 0) = 0;
	c1.at<double>(1, 0) = 0;
	c1.at<double>(2, 0) = 1;

	cv::Mat c2(3, 1, CV_64F);
	c2.at<double>(0, 0) = imageToTest.size().width;
	c2.at<double>(1, 0) = 0;
	c2.at<double>(2, 0) = 1;

	cv::Mat c3(3, 1, CV_64F);
	c3.at<double>(0, 0) = imageToTest.size().width;
	c3.at<double>(1, 0) = imageToTest.size().height;
	c3.at<double>(2, 0) = 1;

	cv::Mat c4(3, 1, CV_64F);
	c4.at<double>(0, 0) = 0;
	c4.at<double>(1, 0) = imageToTest.size().height;
	c4.at<double>(2, 0) = 1;

	//vector of Mats to hold corner points
	std::vector<cv::Mat> corners = { c1, c2, c3, c4};

	//holds the corners that will be iterated over
	int TwoDPoints[8][2];

	//compute new coordinates to find their location in the image by multiplying by the computed Homography
	for (int i = 0; i < 4; i++) {
		//add the points on the matrix mutliplied image to the twoDPoints array
		TwoDPoints[i+4][0] = corners[i].at<double>(0, 0);
		TwoDPoints[i+4][1] = corners[i].at<double>(1, 0);

		//apply matrix multiplication
		corners[i] = H * corners[i];

		//add the matrix multiplied points to the twoDPoints array
		TwoDPoints[i][0] = corners[i].at<double>(0, 0);
		TwoDPoints[i][1] = corners[i].at<double>(1, 0);
	}

	//Now we need to find the min and max points
	int minX = TwoDPoints[0][0], minY = TwoDPoints[0][1];
	int maxX = TwoDPoints[0][0], maxY = TwoDPoints[0][1];

	// Iterate through the array to find min and max values
	for (int i = 0; i < 8; i++) {
		// Update minX and maxX
		if (TwoDPoints[i][0] < minX)
			minX = TwoDPoints[i][0];
		else if (TwoDPoints[i][0] > maxX)
			maxX = TwoDPoints[i][0];

		// Update minY and maxY
		if (TwoDPoints[i][1] < minY)
			minY = TwoDPoints[i][1];
		else if (TwoDPoints[i][1] > maxY)
			maxY = TwoDPoints[i][1];
	}

	//find what size the new frame must be
	double FrameSizeX = maxX - minX;
	double FrameSizeY = maxY - minY;

	//frame the image in a size that fits all the 
	cv::Mat frame(FrameSizeY, FrameSizeX, CV_8UC3);
	cv::Mat mosaic = image1.clone();

	//translation to put image1 in upper righthand conrner
	cv::Mat t1 = translationMatrix(-minX, -minY);
	//Homography warp matrix to put image1 in the image with no cahnges
	cv::Mat t2 = translationMatrix(0, 0);

	//warp the two images into the blank frame large enough to hold them  
	//the order of these translations was messing this up completely ie. t1*t2 and t2*t1 have totally differing effects 
	//took some tinkering to figure that out.
	cv::warpPerspective(image1, mosaic, t1*t2, frame.size(),
		cv::INTER_NEAREST, cv::BORDER_TRANSPARENT);

	cv::warpPerspective(imageToTest, mosaic, t1*H, frame.size(),
		cv::INTER_NEAREST, cv::BORDER_TRANSPARENT);

	//dispay image
	cv::imshow("Image Mosaic", mosaic);
	cv::waitKey();